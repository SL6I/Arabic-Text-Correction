# -*- coding: utf-8 -*-
"""Simple-BaseLine.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11nu8Gp4PuJCf5TDuMbVex5Qkh6X9-nCv

# Import Libraries
"""

import collections

"""# Read Filesd As lines"""

########################################
# READ LINES FROM FILE
########################################
def read_lines(filepath):
    with open(filepath, 'r', encoding='utf-8') as f:
        return [line.strip() for line in f.readlines()]

"""# Simple BaseLine"""

########################################
# 2) BUILD A TOKEN-LEVEL DICTIONARY
########################################
def build_correction_dictionary(train_sent_path, train_cor_path):
    """
    Constructs a dictionary mapping raw tokens to their most frequent corrected tokens.

    Args:
        train_sent_path (str): Path to the raw/erroneous sentences file.
        train_cor_path (str): Path to the corrected sentences file.

    Returns:
        dict: Dictionary mapping raw_token -> most frequent corrected_token
    """
    # Read the raw and corrected lines
    raw_lines = read_lines(train_sent_path)
    cor_lines = read_lines(train_cor_path)

    # Initialize an empty dictionary to store correction frequencies
    freq_map = {}

    # Iterate over each pair of raw and corrected sentences
    for raw, cor in zip(raw_lines, cor_lines):
        # Split sentences into tokens
        raw_tokens = raw.split()
        cor_tokens = cor.split()

        # Compare tokens up to the length of the shorter sentence
        for rt, ct in zip(raw_tokens, cor_tokens):
            if rt != ct:
                if rt not in freq_map:
                    freq_map[rt] = {}
                if ct not in freq_map[rt]:
                    freq_map[rt][ct] = 0
                freq_map[rt][ct] += 1

    # Create the correction dictionary by selecting the most frequent correction for each raw token
    correction_dict = {rt: max(cts, key=cts.get) for rt, cts in freq_map.items()}

    return correction_dict


"""**Apply dictionar**"""

########################################
# APPLY THE DICTIONARY
########################################
def apply_correction_dictionary(sentence, correction_dict):
    """
    Splits a sentence into tokens and uses correction_dict to correct each token if known.
    Returns the corrected sentence (token-based) as a list of tokens.
    """
    tokens = sentence.split()
    corrected_tokens = []
    for tok in tokens:
        if tok in correction_dict:
            corrected_tokens.append(correction_dict[tok])
        else:
            corrected_tokens.append(tok)  # unknown, leave as-is
    return corrected_tokens

"""# Evaluation Function for Precision, Recall, and F1"""

########################################
# 4) EVALUATION: TOKEN-LEVEL PRECISION, RECALL, F1
########################################
def evaluate_precision_recall_f1(raw_lines, ref_lines, correction_dict):
    """
    raw_lines: raw/erroneous sentences (list of strings)
    ref_lines: reference/corrected sentences (list of strings)
    correction_dict: dict for correction
    Returns: (precision, recall, f1)
    """


    # Counters for P/R/F1
    TP = 0  # changed token matches gold
    FP = 0  # changed token does NOT match gold
    FN = 0  # did NOT change token, but gold is different

    for raw_line, ref_line in zip(raw_lines, ref_lines):
        raw_tokens = raw_line.split()
        ref_tokens = ref_line.split()

        # Inference
        pred_tokens = apply_correction_dictionary(raw_line, correction_dict)

        # We'll compare up to min_len tokens for simplicity
        min_len = min(len(raw_tokens), len(ref_tokens), len(pred_tokens))

        for i in range(min_len):
            r_tok = raw_tokens[i]
            ref_tok = ref_tokens[i]
            pred_tok = pred_tokens[i]

            # Did we change this token?
            changed = (pred_tok != r_tok)
            gold_diff = (ref_tok != r_tok)  # gold says it should be changed

            if changed and gold_diff:
                # We changed it, and the gold is also different from raw
                if pred_tok == ref_tok:
                    TP += 1
                else:
                    FP += 1
            elif changed and not gold_diff:
                # We changed it, but gold says it should NOT be changed
                FP += 1
            elif (not changed) and gold_diff:
                # We did NOT change it, but gold is different
                FN += 1
            # if not changed and not gold_diff -> True Negative (we ignore in GEC F1)

    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0
    recall    = TP / (TP + FN) if (TP + FN) > 0 else 0.0
    if precision + recall > 0:
        f1 = 2 * precision * recall / (precision + recall)
    else:
        f1 = 0.0

    return precision, recall, f1

"""# The Main"""

if __name__ == "__main__":

    train_sent = r"C:\Users\SL6\Desktop\S\QALB-0.9.1-Dec03-2021-SharedTasks\data\2014\train\QALB-2014-L1-Train.sent"
    train_cor = r"C:\Users\SL6\Desktop\S\QALB-0.9.1-Dec03-2021-SharedTasks\data\2014\train\QALB-2014-L1-Train.cor"
    dev_sent = r"C:\Users\SL6\Desktop\S\QALB-0.9.1-Dec03-2021-SharedTasks\data\2014\test\QALB-2014-L1-Test.sent"
    dev_cor = r"C:\Users\SL6\Desktop\S\QALB-0.9.1-Dec03-2021-SharedTasks\data\2014\test\QALB-2014-L1-Test.cor"

    # STEP A: BUILD THE DICTIONARY FROM TRAIN
    correction_dict = build_correction_dictionary(train_sent, train_cor)
    print(f"Built dictionary with {len(correction_dict)} entries.")
    # print(correction_dict)
    # STEP B: EVALUATE ON DEV
    dev_raw_lines = read_lines(dev_sent)
    dev_ref_lines = read_lines(dev_cor)

    precision, recall, f1 = evaluate_precision_recall_f1(dev_raw_lines, dev_ref_lines, correction_dict)

    print("=== Baseline Dictionary Model (DEV) ===")
    print(f"Precision: {precision:.3f}")
    print(f"Recall:    {recall:.3f}")
    print(f"F1:        {f1:.3f}")