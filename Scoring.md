## Evaluation Function for Precision, Recall, and F1  
Precision, Recall, and F1 Score are commonly used metrics information retrieval to evaluate the performance of models, especially in classification tasks.  

# Precision
**Definition**: Precision is the percentage of corrections made by the system that are actually correct.
![image alt] 
**Purpose**: Important when unnecessary corrections (false positives) could confuse or degrade text quality.
